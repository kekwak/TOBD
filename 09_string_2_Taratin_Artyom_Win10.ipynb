{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EvK2TwmdcsKx"
   },
   "source": [
    "# Введение в обработку текста на естественном языке"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V4VMM1dCcsK6"
   },
   "source": [
    "Материалы:\n",
    "* Макрушин С.В. Лекция 9: Введение в обработку текста на естественном языке\\\n",
    "* https://realpython.com/nltk-nlp-python/\n",
    "* https://scikit-learn.org/stable/modules/feature_extraction.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qRLm0KHScsK7"
   },
   "source": [
    "## Задачи для совместного разбора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "XsA5IzfqcsK8"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pymorphy2\n",
    "import re\n",
    "from nltk.metrics.distance import (\n",
    "    edit_distance,\n",
    "    edit_distance_align,\n",
    "    binary_distance,\n",
    "    jaccard_distance,\n",
    "    masi_distance,\n",
    "    interval_distance,\n",
    "    custom_distance,\n",
    "    presence,\n",
    "    fractional_presence,\n",
    ")\n",
    "from razdel import sentenize\n",
    "from razdel import tokenize\n",
    "from nltk.stem import SnowballStemmer\n",
    "from sklearn.feature_extraction.text import (CountVectorizer, TfidfVectorizer)\n",
    "import csv\n",
    "import pandas as pd\n",
    "from nltk import word_tokenize\n",
    "from nltk import sent_tokenize\n",
    "import numpy as np\n",
    "from nltk.probability import FreqDist\n",
    "import random\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from scipy.spatial import distance\n",
    "import nltk\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MRZ4--DxcsK-"
   },
   "source": [
    "1. Считайте слова из файла `litw-win.txt` и запишите их в список `words`. В заданном предложении исправьте все опечатки, заменив слова с опечатками на ближайшие (в смысле расстояния Левенштейна) к ним слова из списка `words`. Считайте, что в слове есть опечатка, если данное слово не содержится в списке `words`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "9Sp6REWCcsK_"
   },
   "outputs": [],
   "source": [
    "text = '''с велечайшим усилием выбравшись из потока убегающих людей Кутузов со свитой уменьшевшейся вдвое поехал на звуки выстрелов русских орудий'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['и',\n",
       " 'в',\n",
       " 'я',\n",
       " 'с',\n",
       " 'а',\n",
       " 'к',\n",
       " 'у',\n",
       " 'о',\n",
       " 'н',\n",
       " 'п',\n",
       " 'ж',\n",
       " 'б',\n",
       " 'т',\n",
       " 'д',\n",
       " 'м',\n",
       " 'ч',\n",
       " 'з',\n",
       " 'г',\n",
       " 'е',\n",
       " 'р',\n",
       " 'э',\n",
       " 'л',\n",
       " 'х',\n",
       " 'ш',\n",
       " 'ф',\n",
       " 'ц',\n",
       " 'щ',\n",
       " 'й',\n",
       " 'ю',\n",
       " 'ы',\n",
       " 'ъ',\n",
       " 'ь',\n",
       " 'не',\n",
       " 'на',\n",
       " 'он',\n",
       " 'то',\n",
       " 'но',\n",
       " 'же',\n",
       " 'вы',\n",
       " 'по',\n",
       " 'да',\n",
       " 'за',\n",
       " 'бы',\n",
       " 'ты',\n",
       " 'от',\n",
       " 'из',\n",
       " 'ее',\n",
       " 'до',\n",
       " 'ну',\n",
       " 'ни',\n",
       " 'ли',\n",
       " 'уж',\n",
       " 'во',\n",
       " 'их',\n",
       " 'мы',\n",
       " 'со',\n",
       " 'ей',\n",
       " 'об',\n",
       " 'ко',\n",
       " 'ах',\n",
       " 'им',\n",
       " 'ка',\n",
       " 'та',\n",
       " 'пр',\n",
       " 'те',\n",
       " 'чт',\n",
       " 'ту',\n",
       " 'го',\n",
       " 'де',\n",
       " 'вс',\n",
       " 'эт',\n",
       " 'мо',\n",
       " 'ра',\n",
       " 'ст',\n",
       " 'ха',\n",
       " 'хе',\n",
       " 'ум',\n",
       " 'се',\n",
       " 'эх',\n",
       " 'гм',\n",
       " 'ме',\n",
       " 'св',\n",
       " 'ль',\n",
       " 'ег',\n",
       " 'пе',\n",
       " 'ва',\n",
       " 'са',\n",
       " 'ве',\n",
       " 'ох',\n",
       " 'бо',\n",
       " 'хо',\n",
       " 'че',\n",
       " 'сл',\n",
       " 'од',\n",
       " 'бе',\n",
       " 'мн',\n",
       " 'ай',\n",
       " 'ею',\n",
       " 'ос',\n",
       " 'ск',\n",
       " 'ви',\n",
       " 'ми',\n",
       " 'ма',\n",
       " 'сп',\n",
       " 'ба',\n",
       " 'ес',\n",
       " 'бу',\n",
       " 'гл',\n",
       " 'що',\n",
       " 'эй',\n",
       " 'ем',\n",
       " 'кр',\n",
       " 'см',\n",
       " 'др',\n",
       " 'лю',\n",
       " 'па',\n",
       " 'ро',\n",
       " 'зн',\n",
       " 'ле',\n",
       " 'як',\n",
       " 'тр',\n",
       " 'жи',\n",
       " 'ел',\n",
       " 'ус',\n",
       " 'фу',\n",
       " 'дв',\n",
       " 'ру',\n",
       " 'ал',\n",
       " 'ой',\n",
       " 'си',\n",
       " 'ду',\n",
       " 'вз',\n",
       " 'ещ',\n",
       " 'хи',\n",
       " 'чи',\n",
       " 'вд',\n",
       " 'ил',\n",
       " 'ух',\n",
       " 'ча',\n",
       " 'гр',\n",
       " 'пи',\n",
       " 'бл',\n",
       " 'ре',\n",
       " 'су',\n",
       " 'ге',\n",
       " 'ку',\n",
       " 'оп',\n",
       " 'жа',\n",
       " 'ис',\n",
       " 'оч',\n",
       " 'эк',\n",
       " 'дл',\n",
       " 'пл',\n",
       " 'ин',\n",
       " 'пу',\n",
       " 'фр',\n",
       " 'ан',\n",
       " 'бр',\n",
       " 'чу',\n",
       " 'му',\n",
       " 'ув',\n",
       " 'вп',\n",
       " 'кн',\n",
       " 'ив',\n",
       " 'ок',\n",
       " 'ад',\n",
       " 'лу',\n",
       " 'уг',\n",
       " 'вр',\n",
       " 'ло',\n",
       " 'це',\n",
       " 'гу',\n",
       " 'ла',\n",
       " 'ше',\n",
       " 'ср',\n",
       " 'ти',\n",
       " 'уд',\n",
       " 'фе',\n",
       " 'ди',\n",
       " 'тв',\n",
       " 'гд',\n",
       " 'сд',\n",
       " 'вн',\n",
       " 'ид',\n",
       " 'уб',\n",
       " 'щи',\n",
       " 'зд',\n",
       " 'уп',\n",
       " 'сч',\n",
       " 'уз',\n",
       " 'га',\n",
       " 'ог',\n",
       " 'ул',\n",
       " 'ша',\n",
       " 'ар',\n",
       " 'ут',\n",
       " 'фи',\n",
       " 'аж',\n",
       " 'ед',\n",
       " 'кт',\n",
       " 'гг',\n",
       " 'кл',\n",
       " 'сн',\n",
       " 'ук',\n",
       " 'зе',\n",
       " 'иг',\n",
       " 'зи',\n",
       " 'ки',\n",
       " 'ца',\n",
       " 'яр',\n",
       " 'дн',\n",
       " 'мя',\n",
       " 'сы',\n",
       " 'фа',\n",
       " 'вм',\n",
       " 'зл',\n",
       " 'ож',\n",
       " 'сю',\n",
       " 'шу',\n",
       " 'пя',\n",
       " 'тя',\n",
       " 'шл',\n",
       " 'шт',\n",
       " 'вл',\n",
       " 'ля',\n",
       " 'ор',\n",
       " 'хр',\n",
       " 'ще',\n",
       " 'ак',\n",
       " 'дя',\n",
       " 'ит',\n",
       " 'уч',\n",
       " 'ху',\n",
       " 'ши',\n",
       " 'фо',\n",
       " 'яв',\n",
       " 'би',\n",
       " 'ды',\n",
       " 'ры',\n",
       " 'уй',\n",
       " 'юг',\n",
       " 'вв',\n",
       " 'иб',\n",
       " 'кв',\n",
       " 'сб',\n",
       " 'сх',\n",
       " 'сь',\n",
       " 'зв',\n",
       " 'ол',\n",
       " 'тс',\n",
       " 'яд',\n",
       " 'аз',\n",
       " 'вч',\n",
       " 'ет',\n",
       " 'зу',\n",
       " 'ке',\n",
       " 'хл',\n",
       " 'аг',\n",
       " 'ев',\n",
       " 'еж',\n",
       " 'жд',\n",
       " 'ны',\n",
       " 'ов',\n",
       " 'пь',\n",
       " 'яс',\n",
       " 'вт',\n",
       " 'зо',\n",
       " 'ня',\n",
       " 'оз',\n",
       " 'оф',\n",
       " 'ош',\n",
       " 'ся',\n",
       " 'тю',\n",
       " 'уе',\n",
       " 'ун',\n",
       " 'уш',\n",
       " 'хм',\n",
       " 'ав',\n",
       " 'жу',\n",
       " 'мл',\n",
       " 'мм',\n",
       " 'ри',\n",
       " 'ть',\n",
       " 'чр',\n",
       " 'шк',\n",
       " 'ап',\n",
       " 'ас',\n",
       " 'нр',\n",
       " 'сг',\n",
       " 'сс',\n",
       " 'чш',\n",
       " 'юн',\n",
       " 'яй',\n",
       " 'ам',\n",
       " 'вг',\n",
       " 'ву',\n",
       " 'вх',\n",
       " 'дю',\n",
       " 'км',\n",
       " 'мг',\n",
       " 'ом',\n",
       " 'ощ',\n",
       " 'пы',\n",
       " 'рт',\n",
       " 'рю',\n",
       " 'ря',\n",
       " 'сф',\n",
       " 'сц',\n",
       " 'ур',\n",
       " 'хв',\n",
       " 'шп',\n",
       " 'шю',\n",
       " 'ая',\n",
       " 'бя',\n",
       " 'ги',\n",
       " 'гн',\n",
       " 'дж',\n",
       " 'ер',\n",
       " 'ик',\n",
       " 'ищ',\n",
       " 'съ',\n",
       " 'фл',\n",
       " 'чь',\n",
       " 'шо',\n",
       " 'яз',\n",
       " 'аи',\n",
       " 'ат',\n",
       " 'ау',\n",
       " 'вк',\n",
       " 'вя',\n",
       " 'ие',\n",
       " 'ий',\n",
       " 'кс',\n",
       " 'кх',\n",
       " 'тц',\n",
       " 'уа',\n",
       " 'цв',\n",
       " 'ци',\n",
       " 'эп',\n",
       " 'юх',\n",
       " 'ен',\n",
       " 'еф',\n",
       " 'ех',\n",
       " 'зы',\n",
       " 'иа',\n",
       " 'иж',\n",
       " 'ии',\n",
       " 'ио',\n",
       " 'ип',\n",
       " 'ич',\n",
       " 'лы',\n",
       " 'мс',\n",
       " 'мф',\n",
       " 'нс',\n",
       " 'ое',\n",
       " 'оц',\n",
       " 'пш',\n",
       " 'сж',\n",
       " 'сш',\n",
       " 'тщ',\n",
       " 'уф',\n",
       " 'цо',\n",
       " 'цу',\n",
       " 'чо',\n",
       " 'шш',\n",
       " 'эс',\n",
       " 'юм',\n",
       " 'ют',\n",
       " 'аб',\n",
       " 'аф',\n",
       " 'аш',\n",
       " 'бь',\n",
       " 'бю',\n",
       " 'вш',\n",
       " 'въ',\n",
       " 'гв',\n",
       " 'гю',\n",
       " 'дз',\n",
       " 'дм',\n",
       " 'дь',\n",
       " 'еш',\n",
       " 'жр',\n",
       " 'зг',\n",
       " 'зз',\n",
       " 'зр',\n",
       " 'иу',\n",
       " 'иф',\n",
       " 'кь',\n",
       " 'лб',\n",
       " 'лг',\n",
       " 'лж',\n",
       " 'лт',\n",
       " 'мр',\n",
       " 'мч',\n",
       " 'нь',\n",
       " 'нэ',\n",
       " 'ню',\n",
       " 'пт',\n",
       " 'сз',\n",
       " 'тк',\n",
       " 'тл',\n",
       " 'тт',\n",
       " 'тэ',\n",
       " 'уи',\n",
       " 'ущ',\n",
       " 'ую',\n",
       " 'фэ',\n",
       " 'цы',\n",
       " 'шв',\n",
       " 'шм',\n",
       " 'шь',\n",
       " 'ща',\n",
       " 'щу',\n",
       " 'ые',\n",
       " 'ый',\n",
       " 'ыч',\n",
       " 'эа',\n",
       " 'эл',\n",
       " 'эм',\n",
       " 'эн',\n",
       " 'эф',\n",
       " 'ээ',\n",
       " 'юб',\n",
       " 'юл',\n",
       " 'юс',\n",
       " 'яб',\n",
       " 'ян',\n",
       " 'ят',\n",
       " 'ях',\n",
       " 'ящ',\n",
       " 'что',\n",
       " 'как',\n",
       " 'это',\n",
       " 'все',\n",
       " 'его',\n",
       " 'так',\n",
       " 'она',\n",
       " 'мне',\n",
       " 'еще',\n",
       " 'вот',\n",
       " 'был',\n",
       " 'ему',\n",
       " 'нет',\n",
       " 'уже',\n",
       " 'вас',\n",
       " 'вам',\n",
       " 'или',\n",
       " 'для',\n",
       " 'они',\n",
       " 'тут',\n",
       " 'сам',\n",
       " 'чем',\n",
       " 'раз',\n",
       " 'там',\n",
       " 'где',\n",
       " 'под',\n",
       " 'без',\n",
       " 'ней',\n",
       " 'кто',\n",
       " 'мой',\n",
       " 'ним',\n",
       " 'тем',\n",
       " 'при',\n",
       " 'про',\n",
       " 'нас',\n",
       " 'них',\n",
       " 'мог',\n",
       " 'нее',\n",
       " 'эти',\n",
       " 'тот',\n",
       " 'два',\n",
       " 'том',\n",
       " 'всю',\n",
       " 'над',\n",
       " 'три',\n",
       " 'эту',\n",
       " 'лет',\n",
       " 'нем',\n",
       " 'нам',\n",
       " 'бог',\n",
       " 'вся',\n",
       " 'эта',\n",
       " 'моя',\n",
       " 'мое',\n",
       " 'оно',\n",
       " 'всг',\n",
       " 'пор',\n",
       " 'две',\n",
       " 'наш',\n",
       " 'мои',\n",
       " 'дня',\n",
       " 'тех',\n",
       " 'час',\n",
       " 'дом',\n",
       " 'ибо',\n",
       " 'мою',\n",
       " 'сих',\n",
       " 'нею',\n",
       " 'оба',\n",
       " 'вон',\n",
       " 'той',\n",
       " 'вид',\n",
       " 'год',\n",
       " 'ваш',\n",
       " 'дал',\n",
       " 'сел',\n",
       " 'кое',\n",
       " 'ума',\n",
       " 'сто',\n",
       " 'рад',\n",
       " 'дай',\n",
       " 'обо',\n",
       " 'чай',\n",
       " 'пол',\n",
       " 'рук',\n",
       " 'шел',\n",
       " 'нос',\n",
       " 'дам',\n",
       " 'обе',\n",
       " 'дни',\n",
       " 'сей',\n",
       " 'сон',\n",
       " 'кем',\n",
       " 'муж',\n",
       " 'сын',\n",
       " 'имя',\n",
       " 'жил',\n",
       " 'рот',\n",
       " 'дух',\n",
       " 'сил',\n",
       " 'мир',\n",
       " 'ног',\n",
       " 'уме',\n",
       " 'пан',\n",
       " 'сне',\n",
       " 'ста',\n",
       " 'шею',\n",
       " 'сад',\n",
       " 'чаю',\n",
       " 'изо',\n",
       " 'сво',\n",
       " 'миг',\n",
       " 'век',\n",
       " 'мол',\n",
       " 'пот',\n",
       " 'шум',\n",
       " 'дел',\n",
       " 'дед',\n",
       " 'иди',\n",
       " 'пер',\n",
       " 'лиц',\n",
       " 'сем',\n",
       " 'лес',\n",
       " 'тек',\n",
       " 'шла',\n",
       " 'шаг',\n",
       " 'очи',\n",
       " 'душ',\n",
       " 'суд',\n",
       " 'гор',\n",
       " 'пре',\n",
       " 'тон',\n",
       " 'иду',\n",
       " 'тол',\n",
       " 'лег',\n",
       " 'шли',\n",
       " 'пил',\n",
       " 'зна',\n",
       " 'али',\n",
       " 'ими',\n",
       " 'ком',\n",
       " 'мен',\n",
       " 'рас',\n",
       " 'ухо',\n",
       " 'сию',\n",
       " 'кой',\n",
       " 'уши',\n",
       " 'иль',\n",
       " 'одн',\n",
       " 'бол',\n",
       " 'пос',\n",
       " 'вне',\n",
       " 'буд',\n",
       " 'кот',\n",
       " 'лбу',\n",
       " 'кум',\n",
       " 'аль',\n",
       " 'жду',\n",
       " 'лоб',\n",
       " 'ска',\n",
       " 'сна',\n",
       " 'стр',\n",
       " 'вор',\n",
       " 'шее',\n",
       " 'жив',\n",
       " 'меж',\n",
       " 'гов',\n",
       " 'сие',\n",
       " 'ест',\n",
       " 'лев',\n",
       " 'воз',\n",
       " 'фон',\n",
       " 'мож',\n",
       " 'дру',\n",
       " 'кхи',\n",
       " 'еду',\n",
       " 'себ',\n",
       " 'вел',\n",
       " 'увы',\n",
       " 'жид',\n",
       " 'род',\n",
       " 'теб',\n",
       " 'усы',\n",
       " 'шло',\n",
       " 'пок',\n",
       " 'губ',\n",
       " 'ишь',\n",
       " 'бал',\n",
       " 'ког',\n",
       " 'даж',\n",
       " 'дар',\n",
       " 'зло',\n",
       " 'мно',\n",
       " 'тог',\n",
       " 'быт',\n",
       " 'даю',\n",
       " 'сло',\n",
       " 'теп',\n",
       " 'ост',\n",
       " 'бес',\n",
       " 'нег',\n",
       " 'чин',\n",
       " 'тою',\n",
       " 'хот',\n",
       " 'бек',\n",
       " 'бок',\n",
       " 'гол',\n",
       " 'жен',\n",
       " 'чей',\n",
       " 'вер',\n",
       " 'луч',\n",
       " 'нес',\n",
       " 'поч',\n",
       " 'вдр',\n",
       " 'жар',\n",
       " 'люб',\n",
       " 'опя',\n",
       " 'нож',\n",
       " 'ряд',\n",
       " 'вес',\n",
       " 'гла',\n",
       " 'дым',\n",
       " 'ход',\n",
       " 'всь',\n",
       " 'зла',\n",
       " 'неп',\n",
       " 'чуб',\n",
       " 'рту',\n",
       " 'слу',\n",
       " 'сны',\n",
       " 'чел',\n",
       " 'отв',\n",
       " 'сме',\n",
       " 'ник',\n",
       " 'пар',\n",
       " 'бил',\n",
       " 'есл',\n",
       " 'мал',\n",
       " 'оче',\n",
       " 'рта',\n",
       " 'уст',\n",
       " 'вед',\n",
       " 'кон',\n",
       " 'сия',\n",
       " 'баб',\n",
       " 'пов',\n",
       " 'рай',\n",
       " 'дум',\n",
       " 'дол',\n",
       " 'пра',\n",
       " 'сим',\n",
       " 'дне',\n",
       " 'зам',\n",
       " 'ива',\n",
       " 'име',\n",
       " 'нак',\n",
       " 'пом',\n",
       " 'поп',\n",
       " 'чьи',\n",
       " 'быв',\n",
       " 'дав',\n",
       " 'зол',\n",
       " 'пью',\n",
       " 'шеи',\n",
       " 'ниб',\n",
       " 'сер',\n",
       " 'лжи',\n",
       " 'соб',\n",
       " 'тип',\n",
       " 'шут',\n",
       " 'яко',\n",
       " 'бла',\n",
       " 'вре',\n",
       " 'дна',\n",
       " 'мил',\n",
       " 'нач',\n",
       " 'раб',\n",
       " 'чер',\n",
       " 'чья',\n",
       " 'нап',\n",
       " 'обр',\n",
       " 'сов',\n",
       " 'гос',\n",
       " 'идя',\n",
       " 'пел',\n",
       " 'пет',\n",
       " 'вос',\n",
       " 'ден',\n",
       " 'пал',\n",
       " 'све',\n",
       " 'спи',\n",
       " 'цел',\n",
       " 'бой',\n",
       " 'жиз',\n",
       " 'ищу',\n",
       " 'каж',\n",
       " 'пон',\n",
       " 'суп',\n",
       " 'хор',\n",
       " 'сле',\n",
       " 'лад',\n",
       " 'пир',\n",
       " 'сии',\n",
       " 'бед',\n",
       " 'зал',\n",
       " 'ура',\n",
       " 'але',\n",
       " 'зас',\n",
       " 'кра',\n",
       " 'мес',\n",
       " 'око',\n",
       " 'пус',\n",
       " 'ско',\n",
       " 'эге',\n",
       " 'выс',\n",
       " 'дер',\n",
       " 'рос',\n",
       " 'боя',\n",
       " 'зак',\n",
       " 'кол',\n",
       " 'оди',\n",
       " 'ото',\n",
       " 'пав',\n",
       " 'поз',\n",
       " 'смо',\n",
       " 'спр',\n",
       " 'тих',\n",
       " 'тож',\n",
       " 'заб',\n",
       " 'зав',\n",
       " 'лба',\n",
       " 'мел',\n",
       " 'отк',\n",
       " 'дно',\n",
       " 'зап',\n",
       " 'кня',\n",
       " 'люд',\n",
       " 'мат',\n",
       " 'мая',\n",
       " 'нед',\n",
       " 'пес',\n",
       " 'сос',\n",
       " 'уму',\n",
       " 'чье',\n",
       " 'веч',\n",
       " 'пис',\n",
       " 'уху',\n",
       " 'бар',\n",
       " 'вст',\n",
       " 'гул',\n",
       " 'ища',\n",
       " 'мер',\n",
       " 'наз',\n",
       " 'ром',\n",
       " 'сде',\n",
       " 'спа',\n",
       " 'ага',\n",
       " 'бро',\n",
       " 'доб',\n",
       " 'дов',\n",
       " 'зад',\n",
       " 'кри',\n",
       " 'тре',\n",
       " 'вод',\n",
       " 'ели',\n",
       " 'осо',\n",
       " 'пой',\n",
       " 'рев',\n",
       " 'вин',\n",
       " 'вру',\n",
       " 'дор',\n",
       " 'иск',\n",
       " 'лгу',\n",
       " 'лик',\n",
       " 'нич',\n",
       " 'ужа',\n",
       " 'щек',\n",
       " 'вол',\n",
       " 'дос',\n",
       " 'еле',\n",
       " 'зат',\n",
       " 'ино',\n",
       " 'лат',\n",
       " 'пла',\n",
       " 'пош',\n",
       " 'сор',\n",
       " 'бра',\n",
       " 'гру',\n",
       " 'заг',\n",
       " 'мин',\n",
       " 'нар',\n",
       " 'пож',\n",
       " 'сту',\n",
       " 'точ',\n",
       " 'хоч',\n",
       " 'дев',\n",
       " 'зря',\n",
       " 'меч',\n",
       " 'мыс',\n",
       " 'неу',\n",
       " 'сте',\n",
       " 'улы',\n",
       " 'зде',\n",
       " 'исп',\n",
       " 'кар',\n",
       " 'кро',\n",
       " 'кур',\n",
       " 'лай',\n",
       " 'лед',\n",
       " 'нав',\n",
       " 'нев',\n",
       " 'нео',\n",
       " 'нов',\n",
       " 'ока',\n",
       " 'пуф',\n",
       " 'реш',\n",
       " 'руб',\n",
       " 'сак',\n",
       " 'сок',\n",
       " 'тво',\n",
       " 'уха',\n",
       " 'вск',\n",
       " 'гам',\n",
       " 'ген',\n",
       " 'мед',\n",
       " 'наг',\n",
       " 'отд',\n",
       " 'рус',\n",
       " 'слы',\n",
       " 'взг',\n",
       " 'вой',\n",
       " 'воп',\n",
       " 'выш',\n",
       " 'дон',\n",
       " 'ешь',\n",
       " 'жел',\n",
       " 'зов',\n",
       " 'мук',\n",
       " 'неш',\n",
       " 'ниц',\n",
       " 'обс',\n",
       " 'оне',\n",
       " 'пря',\n",
       " 'сыр',\n",
       " 'уви',\n",
       " 'узн',\n",
       " 'худ',\n",
       " 'эка',\n",
       " 'взд',\n",
       " 'впе',\n",
       " 'гля',\n",
       " 'дуб',\n",
       " 'дур',\n",
       " 'ела',\n",
       " 'игр',\n",
       " 'изб',\n",
       " 'лиш',\n",
       " 'обл',\n",
       " 'ого',\n",
       " 'пей',\n",
       " 'пух',\n",
       " 'пят',\n",
       " 'ран',\n",
       " 'сла',\n",
       " 'тыс',\n",
       " 'укр',\n",
       " 'фед',\n",
       " 'фра',\n",
       " 'щоб',\n",
       " 'бей',\n",
       " 'бык',\n",
       " 'взя',\n",
       " 'гро',\n",
       " 'дво',\n",
       " 'жал',\n",
       " 'изв',\n",
       " 'куд',\n",
       " 'мух',\n",
       " 'ноч',\n",
       " 'пле',\n",
       " 'рак',\n",
       " 'ред',\n",
       " 'чег',\n",
       " 'чув',\n",
       " 'шея',\n",
       " 'бер',\n",
       " 'бор',\n",
       " 'вал',\n",
       " 'вме',\n",
       " 'глу',\n",
       " 'гоп',\n",
       " 'дет',\n",
       " 'док',\n",
       " 'ищи',\n",
       " 'кох',\n",
       " 'кре',\n",
       " 'нах',\n",
       " 'объ',\n",
       " 'ожи',\n",
       " 'тер',\n",
       " 'тро',\n",
       " 'тсс',\n",
       " 'уби',\n",
       " 'чет',\n",
       " 'эко',\n",
       " 'бел',\n",
       " 'быс',\n",
       " 'впр',\n",
       " 'зах',\n",
       " 'кру',\n",
       " 'мар',\n",
       " 'нек',\n",
       " 'нуж',\n",
       " 'поб',\n",
       " 'пог',\n",
       " 'рим',\n",
       " 'роз',\n",
       " 'соо',\n",
       " 'спо',\n",
       " 'сыт',\n",
       " 'тел',\n",
       " 'тра',\n",
       " 'уго',\n",
       " 'чес',\n",
       " 'юге',\n",
       " 'яму',\n",
       " 'бум',\n",
       " 'вез',\n",
       " 'воо',\n",
       " 'гра',\n",
       " 'жан',\n",
       " 'изд',\n",
       " 'кап',\n",
       " 'лех',\n",
       " 'отц',\n",
       " 'раю',\n",
       " 'ров',\n",
       " 'рты',\n",
       " 'сид',\n",
       " 'учи',\n",
       " 'вып',\n",
       " 'гад',\n",
       " 'жди',\n",
       " 'каз',\n",
       " 'кос',\n",
       " 'лез',\n",
       " 'мит',\n",
       " 'неб',\n",
       " 'отр',\n",
       " 'рок',\n",
       " 'рыб',\n",
       " 'сан',\n",
       " 'сек',\n",
       " 'сну',\n",
       " 'уве',\n",
       " 'уди',\n",
       " 'ухе',\n",
       " 'чад',\n",
       " 'чая',\n",
       " 'чис',\n",
       " 'чут',\n",
       " 'акт',\n",
       " 'вов',\n",
       " 'всп',\n",
       " 'дню',\n",
       " 'дул',\n",
       " 'ежа',\n",
       " 'жит',\n",
       " 'зем',\n",
       " 'злы',\n",
       " ...]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('litw-win.txt', 'r') as f:\n",
    "    data = [''.join(line.split()[1]).strip() for line in f]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "text2 = []\n",
    "for i in text.split():\n",
    "    word = i\n",
    "    if word.lower() not in data:\n",
    "        for s in data:\n",
    "            if edit_distance(i, s, substitution_cost=2) < float('inf'):\n",
    "                dist = edit_distance(i, s, substitution_cost=2)\n",
    "                word = s\n",
    "    text2.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'с уменьшившейся усилием выбравшись из потока убегающих людей Кутузов со свитой уменьшившейся вдвое поехал на звуки выстрелов русских орудий'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(text2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yULsGQpacsLA"
   },
   "source": [
    "2. Разбейте текст из формулировки задания 1 на слова; проведите стемминг и лемматизацию слов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7SwcrtwRcsLA"
   },
   "source": [
    "3. Преобразуйте предложения из формулировки задания 1 в векторы при помощи `CountVectorizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Считайте слова из файла litw-win.txt и запишите их в список words.',\n",
       " 'В заданном предложении исправьте все опечатки, заменив слова с опечатками на ближайшие (в смысле расстояния Левенштейна) к ним слова из списка words.',\n",
       " 'Считайте, что в слове есть опечатка, если данное слово не содержится в списке words.']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = list(sentenize('Считайте слова из файла litw-win.txt и запишите их в список words. В заданном предложении исправьте все опечатки, заменив слова с опечатками на ближайшие (в смысле расстояния Левенштейна) к ним слова из списка words. Считайте, что в слове есть опечатка, если данное слово не содержится в списке words.'))\n",
    "text3 = []\n",
    "for i in sent:\n",
    "    text3.append(i.text)\n",
    "text3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0],\n",
       "       [0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1,\n",
       "        1, 1, 2, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n",
       "        0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1]], dtype=int64)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans = CountVectorizer().fit_transform(text3)\n",
    "r = trans.toarray()\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tio9mRCLcsLB"
   },
   "source": [
    "## Лабораторная работа 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "At0bv3jjcsLC"
   },
   "source": [
    "### Расстояние редактирования"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y9b_6xLbcsLC"
   },
   "source": [
    "1.1 Загрузите предобработанные описания рецептов из файла `preprocessed_descriptions.csv`. Получите набор уникальных слов `words`, содержащихся в текстах описаний рецептов (воспользуйтесь `word_tokenize` из `nltk`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>preprocessed_descriptions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>george s at the cove  black bean soup</td>\n",
       "      <td>an original recipe created by chef scott meska...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>healthy for them  yogurt popsicles</td>\n",
       "      <td>my children and their friends ask for my homem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i can t believe it s spinach</td>\n",
       "      <td>these were so go it surprised even me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>italian  gut busters</td>\n",
       "      <td>my sisterinlaw made these for us at a family g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>love is in the air  beef fondue   sauces</td>\n",
       "      <td>i think a fondue is a very romantic casual din...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29995</th>\n",
       "      <td>zurie s holey rustic olive and cheddar bread</td>\n",
       "      <td>this is based on a french recipe but i changed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29996</th>\n",
       "      <td>zwetschgenkuchen  bavarian plum cake</td>\n",
       "      <td>this is a traditional fresh plum cake thought ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29997</th>\n",
       "      <td>zwiebelkuchen   southwest german onion cake</td>\n",
       "      <td>this is a traditional late summer early fall s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29998</th>\n",
       "      <td>zydeco soup</td>\n",
       "      <td>this is a delicious soup that i originally fou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29999</th>\n",
       "      <td>cookies by design   cookies on a stick</td>\n",
       "      <td>ive heard of the cookies by design company but...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               name   \n",
       "0             george s at the cove  black bean soup  \\\n",
       "1                healthy for them  yogurt popsicles   \n",
       "2                      i can t believe it s spinach   \n",
       "3                              italian  gut busters   \n",
       "4          love is in the air  beef fondue   sauces   \n",
       "...                                             ...   \n",
       "29995  zurie s holey rustic olive and cheddar bread   \n",
       "29996          zwetschgenkuchen  bavarian plum cake   \n",
       "29997   zwiebelkuchen   southwest german onion cake   \n",
       "29998                                   zydeco soup   \n",
       "29999        cookies by design   cookies on a stick   \n",
       "\n",
       "                               preprocessed_descriptions  \n",
       "0      an original recipe created by chef scott meska...  \n",
       "1      my children and their friends ask for my homem...  \n",
       "2                  these were so go it surprised even me  \n",
       "3      my sisterinlaw made these for us at a family g...  \n",
       "4      i think a fondue is a very romantic casual din...  \n",
       "...                                                  ...  \n",
       "29995  this is based on a french recipe but i changed...  \n",
       "29996  this is a traditional fresh plum cake thought ...  \n",
       "29997  this is a traditional late summer early fall s...  \n",
       "29998  this is a delicious soup that i originally fou...  \n",
       "29999  ive heard of the cookies by design company but...  \n",
       "\n",
       "[30000 rows x 2 columns]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "description = pd.read_csv('preprocessed_descriptions.csv')\n",
    "description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        an original recipe created by chef scott meska...\n",
       "1        my children and their friends ask for my homem...\n",
       "2                    these were so go it surprised even me\n",
       "3        my sisterinlaw made these for us at a family g...\n",
       "4        i think a fondue is a very romantic casual din...\n",
       "                               ...                        \n",
       "29995    this is based on a french recipe but i changed...\n",
       "29996    this is a traditional fresh plum cake thought ...\n",
       "29997    this is a traditional late summer early fall s...\n",
       "29998    this is a delicious soup that i originally fou...\n",
       "29999    ive heard of the cookies by design company but...\n",
       "Name: preprocessed_descriptions, Length: 30000, dtype: object"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "description.preprocessed_descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['an',\n",
       " 'original',\n",
       " 'recipe',\n",
       " 'created',\n",
       " 'by',\n",
       " 'chef',\n",
       " 'scott',\n",
       " 'meskan',\n",
       " 'georges',\n",
       " 'at',\n",
       " 'the',\n",
       " 'cove',\n",
       " 'we',\n",
       " 'enjoyed',\n",
       " 'this',\n",
       " 'when',\n",
       " 'we',\n",
       " 'visited',\n",
       " 'this',\n",
       " 'restaurant',\n",
       " 'in',\n",
       " 'la',\n",
       " 'jolla',\n",
       " 'california',\n",
       " 'this',\n",
       " 'recipe',\n",
       " 'is',\n",
       " 'requested',\n",
       " 'so',\n",
       " 'often',\n",
       " 'they',\n",
       " 'have',\n",
       " 'it',\n",
       " 'printed',\n",
       " 'and',\n",
       " 'ready',\n",
       " 'at',\n",
       " 'the',\n",
       " 'hostess',\n",
       " 'stand',\n",
       " 'its',\n",
       " 'unbeatable',\n",
       " 'at',\n",
       " 'the',\n",
       " 'restaurant',\n",
       " 'but',\n",
       " 'i',\n",
       " 'do',\n",
       " 'a',\n",
       " 'pretty',\n",
       " 'good',\n",
       " 'job',\n",
       " 'at',\n",
       " 'home',\n",
       " 'too',\n",
       " 'if',\n",
       " 'i',\n",
       " 'do',\n",
       " 'say',\n",
       " 'so',\n",
       " 'myself',\n",
       " 'my',\n",
       " 'children',\n",
       " 'and',\n",
       " 'their',\n",
       " 'friends',\n",
       " 'ask',\n",
       " 'for',\n",
       " 'my',\n",
       " 'homemade',\n",
       " 'popsicles',\n",
       " 'morning',\n",
       " 'noon',\n",
       " 'and',\n",
       " 'night',\n",
       " 'i',\n",
       " 'never',\n",
       " 'turn',\n",
       " 'them',\n",
       " 'down',\n",
       " 'who',\n",
       " 'am',\n",
       " 'i',\n",
       " 'to',\n",
       " 'tell',\n",
       " 'them',\n",
       " 'that',\n",
       " 'they',\n",
       " 'are',\n",
       " 'good',\n",
       " 'for',\n",
       " 'them',\n",
       " 'for',\n",
       " 'variety',\n",
       " 'i',\n",
       " 'substitute',\n",
       " 'different',\n",
       " 'flavours',\n",
       " 'of',\n",
       " 'frozen',\n",
       " 'juice',\n",
       " 'grape',\n",
       " 'fruit',\n",
       " 'punch',\n",
       " 'tropical',\n",
       " 'etc',\n",
       " 'these',\n",
       " 'were',\n",
       " 'so',\n",
       " 'go',\n",
       " 'it',\n",
       " 'surprised',\n",
       " 'even',\n",
       " 'me',\n",
       " 'my',\n",
       " 'sisterinlaw',\n",
       " 'made',\n",
       " 'these',\n",
       " 'for',\n",
       " 'us',\n",
       " 'at',\n",
       " 'a',\n",
       " 'family',\n",
       " 'get',\n",
       " 'together',\n",
       " 'they',\n",
       " 'are',\n",
       " 'delicious',\n",
       " 'a',\n",
       " 'little',\n",
       " 'messy',\n",
       " 'to',\n",
       " 'make',\n",
       " 'but',\n",
       " 'worth',\n",
       " 'the',\n",
       " 'effort',\n",
       " 'have',\n",
       " 'a',\n",
       " 'helper',\n",
       " 'and',\n",
       " 'make',\n",
       " 'an',\n",
       " 'i',\n",
       " 'think',\n",
       " 'a',\n",
       " 'fondue',\n",
       " 'is',\n",
       " 'a',\n",
       " 'very',\n",
       " 'romantic',\n",
       " 'casual',\n",
       " 'dinner',\n",
       " 'or',\n",
       " 'wonderful',\n",
       " 'for',\n",
       " 'after',\n",
       " 'the',\n",
       " 'theatre',\n",
       " 'snack',\n",
       " 'served',\n",
       " 'with',\n",
       " 'a',\n",
       " 'robust',\n",
       " 'red',\n",
       " 'wine',\n",
       " 'for',\n",
       " 'dinner',\n",
       " 'serve',\n",
       " 'with',\n",
       " 'rice',\n",
       " 'a',\n",
       " 'small',\n",
       " 'salad',\n",
       " 'almond',\n",
       " 'rice',\n",
       " 'pilaf',\n",
       " 'is',\n",
       " 'a',\n",
       " 'great',\n",
       " 'accompaniment',\n",
       " 'recipe',\n",
       " 'posted',\n",
       " 'separately',\n",
       " 'to',\n",
       " 'cook',\n",
       " 'the',\n",
       " 'meat',\n",
       " 'you',\n",
       " 'must',\n",
       " 'first',\n",
       " 'heat',\n",
       " 'your',\n",
       " 'oil',\n",
       " 'i',\n",
       " 'do',\n",
       " 'this',\n",
       " 'by',\n",
       " 'heating',\n",
       " 'it',\n",
       " 'to',\n",
       " 'almost',\n",
       " 'boiling',\n",
       " 'on',\n",
       " 'the',\n",
       " 'stove',\n",
       " 'and',\n",
       " 'then',\n",
       " 'transfering',\n",
       " 'it',\n",
       " 'to',\n",
       " 'your',\n",
       " 'fondue',\n",
       " 'burner',\n",
       " 'buy',\n",
       " 'good',\n",
       " 'quality',\n",
       " 'meat',\n",
       " 'i',\n",
       " 'recommend',\n",
       " 'only',\n",
       " 'using',\n",
       " 'a',\n",
       " 'fillet',\n",
       " 'have',\n",
       " 'at',\n",
       " 'least',\n",
       " 'sauces',\n",
       " 'if',\n",
       " 'you',\n",
       " 'want',\n",
       " 'to',\n",
       " 'serve',\n",
       " 'people',\n",
       " 'just',\n",
       " 'increase',\n",
       " 'the',\n",
       " 'meat',\n",
       " 'to',\n",
       " 'lbs',\n",
       " 'there',\n",
       " 'will',\n",
       " 'be',\n",
       " 'enough',\n",
       " 'saucethese',\n",
       " 'sauce',\n",
       " 'recipes',\n",
       " 'came',\n",
       " 'from',\n",
       " 'ok',\n",
       " 'my',\n",
       " 'heritage',\n",
       " 'has',\n",
       " 'been',\n",
       " 'revealed',\n",
       " 'these',\n",
       " 'are',\n",
       " 'simply',\n",
       " 'wonderful',\n",
       " 'a',\n",
       " 'favorite',\n",
       " 'among',\n",
       " 'our',\n",
       " 'community',\n",
       " 'theyre',\n",
       " 'sure',\n",
       " 'to',\n",
       " 'bring',\n",
       " 'a',\n",
       " 'smile',\n",
       " 'to',\n",
       " 'your',\n",
       " 'face',\n",
       " 'enjoy',\n",
       " 'this',\n",
       " 'is',\n",
       " 'a',\n",
       " 'very',\n",
       " 'versatile',\n",
       " 'and',\n",
       " 'widely',\n",
       " 'enjoyed',\n",
       " 'pasta',\n",
       " 'dish',\n",
       " 'with',\n",
       " 'chicken',\n",
       " 'it',\n",
       " 'has',\n",
       " 'an',\n",
       " 'asian',\n",
       " 'influence',\n",
       " 'with',\n",
       " 'a',\n",
       " 'very',\n",
       " 'nice',\n",
       " 'sesame',\n",
       " 'flavor',\n",
       " 'i',\n",
       " 'whipped',\n",
       " 'it',\n",
       " 'up',\n",
       " 'one',\n",
       " 'evening',\n",
       " 'with',\n",
       " 'a',\n",
       " 'limited',\n",
       " 'pantry',\n",
       " 'and',\n",
       " 'my',\n",
       " 'little',\n",
       " 'one',\n",
       " 'named',\n",
       " 'it',\n",
       " 'joint',\n",
       " 'collaboration',\n",
       " 'on',\n",
       " 'this',\n",
       " 'one',\n",
       " 'folks',\n",
       " 'oh',\n",
       " 'yea',\n",
       " 'and',\n",
       " 'the',\n",
       " 'key',\n",
       " 'is',\n",
       " 'with',\n",
       " 'the',\n",
       " 'fresh',\n",
       " 'ginger',\n",
       " 'you',\n",
       " 'just',\n",
       " 'have',\n",
       " 'to',\n",
       " 'try',\n",
       " 'it',\n",
       " 'to',\n",
       " 'believe',\n",
       " 'it',\n",
       " 'this',\n",
       " 'is',\n",
       " 'the',\n",
       " 'recipe',\n",
       " 'that',\n",
       " 'we',\n",
       " 'use',\n",
       " 'at',\n",
       " 'my',\n",
       " 'school',\n",
       " 'cafeteria',\n",
       " 'for',\n",
       " 'chocolate',\n",
       " 'chip',\n",
       " 'cookies',\n",
       " 'they',\n",
       " 'must',\n",
       " 'be',\n",
       " 'the',\n",
       " 'best',\n",
       " 'chocolate',\n",
       " 'chip',\n",
       " 'cookies',\n",
       " 'i',\n",
       " 'have',\n",
       " 'ever',\n",
       " 'had',\n",
       " 'if',\n",
       " 'you',\n",
       " 'dont',\n",
       " 'have',\n",
       " 'margarine',\n",
       " 'or',\n",
       " 'dont',\n",
       " 'like',\n",
       " 'it',\n",
       " 'then',\n",
       " 'just',\n",
       " 'use',\n",
       " 'butter',\n",
       " 'softened',\n",
       " 'instead',\n",
       " 'since',\n",
       " 'there',\n",
       " 'are',\n",
       " 'already',\n",
       " 'recipes',\n",
       " 'for',\n",
       " 'broccoli',\n",
       " 'casserole',\n",
       " 'posted',\n",
       " 'to',\n",
       " 'zaar',\n",
       " 'i',\n",
       " 'decided',\n",
       " 'to',\n",
       " 'call',\n",
       " 'this',\n",
       " 'one',\n",
       " 'broccoli',\n",
       " 'casserolei',\n",
       " 'dont',\n",
       " 'think',\n",
       " 'there',\n",
       " 'are',\n",
       " 'any',\n",
       " 'like',\n",
       " 'this',\n",
       " 'one',\n",
       " 'in',\n",
       " 'the',\n",
       " 'database',\n",
       " 'i',\n",
       " 'based',\n",
       " 'this',\n",
       " 'one',\n",
       " 'on',\n",
       " 'the',\n",
       " 'famous',\n",
       " 'green',\n",
       " 'bean',\n",
       " 'casserole',\n",
       " 'from',\n",
       " 'campbells',\n",
       " 'soup',\n",
       " 'but',\n",
       " 'i',\n",
       " 'think',\n",
       " 'mine',\n",
       " 'is',\n",
       " 'better',\n",
       " 'since',\n",
       " 'i',\n",
       " 'dont',\n",
       " 'like',\n",
       " 'cream',\n",
       " 'of',\n",
       " 'mushroom',\n",
       " 'soupsubmitted',\n",
       " 'to',\n",
       " 'zaar',\n",
       " 'on',\n",
       " 'may',\n",
       " 'this',\n",
       " 'is',\n",
       " 'a',\n",
       " 'recipe',\n",
       " 'that',\n",
       " 'my',\n",
       " 'mother',\n",
       " 'got',\n",
       " 'from',\n",
       " 'some',\n",
       " 'cooking',\n",
       " 'contest',\n",
       " 'in',\n",
       " 'the',\n",
       " 'it',\n",
       " 'is',\n",
       " 'delicious',\n",
       " 'and',\n",
       " 'filling',\n",
       " 'on',\n",
       " 'a',\n",
       " 'cold',\n",
       " 'night',\n",
       " 'we',\n",
       " 'all',\n",
       " 'loved',\n",
       " 'it',\n",
       " 'so',\n",
       " 'much',\n",
       " 'that',\n",
       " 'we',\n",
       " 'would',\n",
       " 'call',\n",
       " 'it',\n",
       " 'the',\n",
       " 'billion',\n",
       " 'dollar',\n",
       " 'casserole',\n",
       " 'unfortunately',\n",
       " 'my',\n",
       " 'family',\n",
       " 'isnt',\n",
       " 'big',\n",
       " 'on',\n",
       " 'dumplings',\n",
       " 'so',\n",
       " 'i',\n",
       " 'cant',\n",
       " 'make',\n",
       " 'this',\n",
       " 'as',\n",
       " 'often',\n",
       " 'as',\n",
       " 'i',\n",
       " 'would',\n",
       " 'like',\n",
       " 'these',\n",
       " 'are',\n",
       " 'great',\n",
       " 'the',\n",
       " 'perfect',\n",
       " 'name',\n",
       " 'for',\n",
       " 'them',\n",
       " 'i',\n",
       " 'made',\n",
       " 'this',\n",
       " 'recipe',\n",
       " 'myself',\n",
       " 'when',\n",
       " 'i',\n",
       " 'was',\n",
       " 'i',\n",
       " 'was',\n",
       " 'on',\n",
       " 'here',\n",
       " 'trying',\n",
       " 'to',\n",
       " 'find',\n",
       " 'a',\n",
       " 'recipe',\n",
       " 'for',\n",
       " 'potato',\n",
       " 'soup',\n",
       " 'because',\n",
       " 'i',\n",
       " 'liked',\n",
       " 'my',\n",
       " 'moms',\n",
       " 'so',\n",
       " 'much',\n",
       " 'when',\n",
       " 'i',\n",
       " 'was',\n",
       " 'looking',\n",
       " 'i',\n",
       " 'couldnt',\n",
       " 'find',\n",
       " 'a',\n",
       " 'simple',\n",
       " 'recipe',\n",
       " 'for',\n",
       " 'it',\n",
       " 'that',\n",
       " 'looked',\n",
       " 'good',\n",
       " 'so',\n",
       " 'i',\n",
       " 'decided',\n",
       " 'to',\n",
       " 'make',\n",
       " 'my',\n",
       " 'own',\n",
       " 'now',\n",
       " 'my',\n",
       " 'soup',\n",
       " 'tastes',\n",
       " 'even',\n",
       " 'better',\n",
       " 'than',\n",
       " 'my',\n",
       " 'moms',\n",
       " 'and',\n",
       " 'i',\n",
       " 'always',\n",
       " 'make',\n",
       " 'it',\n",
       " 'for',\n",
       " 'family',\n",
       " 'this',\n",
       " 'recipe',\n",
       " 'has',\n",
       " 'been',\n",
       " 'posted',\n",
       " 'here',\n",
       " 'for',\n",
       " 'play',\n",
       " 'in',\n",
       " 'scandinavia',\n",
       " 'this',\n",
       " 'recipe',\n",
       " 'was',\n",
       " 'found',\n",
       " 'at',\n",
       " 'website',\n",
       " 'mindspringcom',\n",
       " 'christians',\n",
       " 'danish',\n",
       " 'recipes',\n",
       " 'this',\n",
       " 'is',\n",
       " 'a',\n",
       " 'neverfail',\n",
       " 'muffin',\n",
       " 'recipe',\n",
       " 'its',\n",
       " 'a',\n",
       " 'blank',\n",
       " 'canvas',\n",
       " 'for',\n",
       " 'anything',\n",
       " 'you',\n",
       " 'can',\n",
       " 'dream',\n",
       " 'up',\n",
       " 'i',\n",
       " 'like',\n",
       " 'coconut',\n",
       " 'and',\n",
       " 'canned',\n",
       " 'chopped',\n",
       " 'pineapple',\n",
       " 'that',\n",
       " 'has',\n",
       " 'been',\n",
       " 'well',\n",
       " 'drained',\n",
       " 'you',\n",
       " 'choose',\n",
       " 'what',\n",
       " 'you',\n",
       " 'want',\n",
       " 'to',\n",
       " 'add',\n",
       " 'in',\n",
       " 'if',\n",
       " 'you',\n",
       " 'like',\n",
       " 'a',\n",
       " 'sweet',\n",
       " 'muffin',\n",
       " 'add',\n",
       " 'in',\n",
       " 'more',\n",
       " 'sugar',\n",
       " 'this',\n",
       " 'is',\n",
       " 'again',\n",
       " 'from',\n",
       " 'vegwebcom',\n",
       " 'this',\n",
       " 'got',\n",
       " 'absolutely',\n",
       " 'amazing',\n",
       " 'reviews',\n",
       " 'over',\n",
       " 'there',\n",
       " 'so',\n",
       " 'im',\n",
       " 'guessing',\n",
       " 'its',\n",
       " 'pretty',\n",
       " 'darn',\n",
       " 'good',\n",
       " 'multiple',\n",
       " 'users',\n",
       " 'said',\n",
       " 'it',\n",
       " 'would',\n",
       " 'even',\n",
       " 'fool',\n",
       " 'the',\n",
       " 'dairy',\n",
       " 'lovers',\n",
       " 'a',\n",
       " 'few',\n",
       " 'users',\n",
       " 'suggested',\n",
       " 'only',\n",
       " 'using',\n",
       " 'half',\n",
       " 'the',\n",
       " 'recommended',\n",
       " 'amount',\n",
       " 'of',\n",
       " 'tofu',\n",
       " 'container',\n",
       " 'others',\n",
       " 'said',\n",
       " 'they',\n",
       " 'used',\n",
       " 'turbinado',\n",
       " 'sugar',\n",
       " 'in',\n",
       " 'place',\n",
       " 'of',\n",
       " 'the',\n",
       " 'syrup',\n",
       " 'cant',\n",
       " 'wait',\n",
       " 'to',\n",
       " 'try',\n",
       " 'it',\n",
       " 'lem',\n",
       " 'me',\n",
       " 'know',\n",
       " 'what',\n",
       " 'you',\n",
       " 'think',\n",
       " 'ok',\n",
       " 'there',\n",
       " 'are',\n",
       " 'different',\n",
       " 'version',\n",
       " 'of',\n",
       " 'burek',\n",
       " 'some',\n",
       " 'eastern',\n",
       " 'europeans',\n",
       " 'even',\n",
       " 'greeks',\n",
       " 'roll',\n",
       " 'a',\n",
       " 'fresh',\n",
       " 'dough',\n",
       " 'and',\n",
       " 'then',\n",
       " 'spend',\n",
       " 'more',\n",
       " 'time',\n",
       " 'rolling',\n",
       " 'folding',\n",
       " 'and',\n",
       " 'waiting',\n",
       " 'but',\n",
       " 'if',\n",
       " 'youre',\n",
       " 'like',\n",
       " 'me',\n",
       " 'and',\n",
       " 'my',\n",
       " 'mom',\n",
       " 'use',\n",
       " 'phyllo',\n",
       " 'its',\n",
       " 'quick',\n",
       " 'and',\n",
       " 'you',\n",
       " 'can',\n",
       " 'always',\n",
       " 'keep',\n",
       " 'it',\n",
       " 'in',\n",
       " 'the',\n",
       " 'freezer',\n",
       " 'i',\n",
       " 'remember',\n",
       " 'while',\n",
       " 'i',\n",
       " 'was',\n",
       " 'growing',\n",
       " 'up',\n",
       " 'and',\n",
       " 'my',\n",
       " 'mom',\n",
       " 'would',\n",
       " 'make',\n",
       " 'this',\n",
       " 'every',\n",
       " 'sunday',\n",
       " 'the',\n",
       " 'smell',\n",
       " 'alone',\n",
       " 'coming',\n",
       " 'from',\n",
       " 'our',\n",
       " 'kitchen',\n",
       " 'used',\n",
       " 'to',\n",
       " 'make',\n",
       " 'me',\n",
       " 'come',\n",
       " 'running',\n",
       " 'home',\n",
       " 'please',\n",
       " 'excuse',\n",
       " 'the',\n",
       " 'directions',\n",
       " 'but',\n",
       " 'the',\n",
       " 'recipe',\n",
       " 'doesnt',\n",
       " 'really',\n",
       " 'have',\n",
       " 'measurements',\n",
       " 'or',\n",
       " 'written',\n",
       " 'directions',\n",
       " 'this',\n",
       " 'is',\n",
       " 'an',\n",
       " 'old',\n",
       " 'recipe',\n",
       " 'and',\n",
       " 'no',\n",
       " 'one',\n",
       " 'ever',\n",
       " 'wrote',\n",
       " 'it',\n",
       " 'down',\n",
       " 'tender',\n",
       " 'garlicky',\n",
       " 'and',\n",
       " 'full',\n",
       " 'of',\n",
       " 'oregano',\n",
       " 'n',\n",
       " 'stuff',\n",
       " 'start',\n",
       " 'this',\n",
       " 'one',\n",
       " 'a',\n",
       " 'day',\n",
       " 'ahead',\n",
       " 'the',\n",
       " 'beef',\n",
       " 'slices',\n",
       " 'need',\n",
       " 'an',\n",
       " 'overnight',\n",
       " 'stay',\n",
       " 'in',\n",
       " 'da',\n",
       " 'gravy',\n",
       " 'to',\n",
       " 'be',\n",
       " 'at',\n",
       " 'their',\n",
       " 'best',\n",
       " 'and',\n",
       " 'please',\n",
       " 'dont',\n",
       " 'overcook',\n",
       " 'the',\n",
       " 'roast',\n",
       " 'as',\n",
       " 'it',\n",
       " 'rests',\n",
       " 'right',\n",
       " 'out',\n",
       " 'of',\n",
       " 'the',\n",
       " 'oven',\n",
       " 'and',\n",
       " 'as',\n",
       " 'its',\n",
       " 'reheated',\n",
       " 'itll',\n",
       " 'stop',\n",
       " 'mooing',\n",
       " 'serve',\n",
       " 'on',\n",
       " 'crusty',\n",
       " 'italian',\n",
       " 'sandwich',\n",
       " 'rolls',\n",
       " 'add',\n",
       " 'sauteed',\n",
       " 'peppers',\n",
       " 'if',\n",
       " 'you',\n",
       " 'like',\n",
       " 'but',\n",
       " 'too',\n",
       " 'much',\n",
       " 'more',\n",
       " 'and',\n",
       " 'it',\n",
       " 'starts',\n",
       " 'looking',\n",
       " 'like',\n",
       " 'a',\n",
       " 'philly',\n",
       " 'steak',\n",
       " 'n',\n",
       " 'cheese',\n",
       " 'a',\n",
       " 'whole',\n",
       " 'other',\n",
       " 'beast',\n",
       " 'prep',\n",
       " 'time',\n",
       " 'includes',\n",
       " 'overnight',\n",
       " 'marinating',\n",
       " 'this',\n",
       " 'is',\n",
       " 'something',\n",
       " 'my',\n",
       " 'grandma',\n",
       " 'made',\n",
       " 'at',\n",
       " 'christmas',\n",
       " 'i',\n",
       " 'dont',\n",
       " 'know',\n",
       " 'where',\n",
       " 'she',\n",
       " 'originally',\n",
       " 'got',\n",
       " 'the',\n",
       " 'recipe',\n",
       " 'but',\n",
       " 'the',\n",
       " 'recipe',\n",
       " 'card',\n",
       " 'for',\n",
       " 'it',\n",
       " 'has',\n",
       " 'her',\n",
       " 'handwriting',\n",
       " 'on',\n",
       " 'it',\n",
       " 'i',\n",
       " 'call',\n",
       " 'them',\n",
       " 'german',\n",
       " 'carrots',\n",
       " 'because',\n",
       " 'grandmas',\n",
       " 'grandparents',\n",
       " 'came',\n",
       " 'over',\n",
       " 'from',\n",
       " 'germany',\n",
       " 'my',\n",
       " 'family',\n",
       " 'mostly',\n",
       " 'eats',\n",
       " 'these',\n",
       " 'at',\n",
       " 'christmas',\n",
       " 'and',\n",
       " 'we',\n",
       " 'usually',\n",
       " 'fight',\n",
       " 'over',\n",
       " 'who',\n",
       " 'gets',\n",
       " 'the',\n",
       " 'little',\n",
       " 'bit',\n",
       " 'thats',\n",
       " 'leftover',\n",
       " 'its',\n",
       " 'a',\n",
       " 'really',\n",
       " 'good',\n",
       " 'barbecued',\n",
       " 'carrot',\n",
       " 'recipe',\n",
       " 'i',\n",
       " 'made',\n",
       " 'this',\n",
       " 'once',\n",
       " 'hoping',\n",
       " 'to',\n",
       " 'have',\n",
       " 'something',\n",
       " 'light',\n",
       " 'for',\n",
       " 'lunch',\n",
       " 'not',\n",
       " 'only',\n",
       " 'was',\n",
       " 'it',\n",
       " 'easy',\n",
       " 'but',\n",
       " 'it',\n",
       " 'tasted',\n",
       " 'great',\n",
       " 'and',\n",
       " 'the',\n",
       " 'bulk',\n",
       " 'of',\n",
       " 'the',\n",
       " 'rice',\n",
       " 'kept',\n",
       " 'me',\n",
       " 'full',\n",
       " 'for',\n",
       " 'hours',\n",
       " 'my',\n",
       " 'old',\n",
       " 'friend',\n",
       " 'pat',\n",
       " 'gave',\n",
       " 'me',\n",
       " 'this',\n",
       " 'recipe',\n",
       " 'years',\n",
       " 'ago',\n",
       " 'and',\n",
       " 'i',\n",
       " 'really',\n",
       " 'love',\n",
       " 'these',\n",
       " 'easy',\n",
       " 'puffsa',\n",
       " ...]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = []\n",
    "w = re.compile('^[a-z]*$')\n",
    "for d in description.preprocessed_descriptions:\n",
    "    words.extend([t.lower() for t in word_tokenize(str(d)) if w.search(t)])\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'the': 40072, 'a': 34951, 'and': 30245, 'this': 26859, 'i': 24836, 'to': 23471, 'is': 20285, 'it': 19756, 'of': 18364, 'for': 15939, ...})"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FD = FreqDist(words)\n",
    "FD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30743"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = len(set(words))\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ckulhf2ZcsLD"
   },
   "source": [
    "1.2 Сгенерируйте 5 пар случайно выбранных слов и посчитайте между ними расстояние редактирования."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['my', 'but', 'bon', 'candies', 'topped']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_words = random.sample(words, 5)\n",
    "n_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my => my: 0\n",
      "my => but: 5\n",
      "my => bon: 5\n",
      "my => candies: 9\n",
      "my => topped: 8\n",
      "but => my: 5\n",
      "but => but: 0\n",
      "but => bon: 4\n",
      "but => candies: 10\n",
      "but => topped: 7\n",
      "bon => my: 5\n",
      "bon => but: 4\n",
      "bon => bon: 0\n",
      "bon => candies: 8\n",
      "bon => topped: 7\n",
      "candies => my: 9\n",
      "candies => but: 10\n",
      "candies => bon: 8\n",
      "candies => candies: 0\n",
      "candies => topped: 11\n",
      "topped => my: 8\n",
      "topped => but: 7\n",
      "topped => bon: 7\n",
      "topped => candies: 11\n",
      "topped => topped: 0\n"
     ]
    }
   ],
   "source": [
    "p = list(itertools.product(range(5), range(5)))\n",
    "for i in p:\n",
    "    print(f'{n_words[i[0]]} => {n_words[i[1]]}: {edit_distance(n_words[i[0]], n_words[i[1]], substitution_cost=2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nfHlU4yOcsLD"
   },
   "source": [
    "1.3 Напишите функцию, которая для заданного слова `word` возвращает `k` ближайших к нему слов из списка `words` (близость слов измеряется с помощью расстояния Левенштейна)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xEGqbapEcsLE"
   },
   "source": [
    "### Стемминг, лемматизация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hAGgb9ducsLE"
   },
   "source": [
    "2.1 На основе результатов 1.1 создайте `pd.DataFrame` со столбцами: \n",
    "    * word\n",
    "    * stemmed_word \n",
    "    * normalized_word \n",
    "\n",
    "Столбец `word` укажите в качестве индекса. \n",
    "\n",
    "Для стемминга воспользуйтесь `SnowballStemmer`, для нормализации слов - `WordNetLemmatizer`. Сравните результаты стемминга и лемматизации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>stemmed_word</th>\n",
       "      <th>normalized_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>and</td>\n",
       "      <td>and</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>this</td>\n",
       "      <td>this</td>\n",
       "      <td>this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i</td>\n",
       "      <td>i</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30738</th>\n",
       "      <td>substantially</td>\n",
       "      <td>substanti</td>\n",
       "      <td>substantially</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30739</th>\n",
       "      <td>mixedgreens</td>\n",
       "      <td>mixedgreen</td>\n",
       "      <td>mixedgreens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30740</th>\n",
       "      <td>augsburg</td>\n",
       "      <td>augsburg</td>\n",
       "      <td>augsburg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30741</th>\n",
       "      <td>consensus</td>\n",
       "      <td>consensus</td>\n",
       "      <td>consensus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30742</th>\n",
       "      <td>planted</td>\n",
       "      <td>plant</td>\n",
       "      <td>planted</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30743 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                word stemmed_word normalized_word\n",
       "0                the          the             the\n",
       "1                  a            a               a\n",
       "2                and          and             and\n",
       "3               this         this            this\n",
       "4                  i            i               i\n",
       "...              ...          ...             ...\n",
       "30738  substantially    substanti   substantially\n",
       "30739    mixedgreens   mixedgreen     mixedgreens\n",
       "30740       augsburg     augsburg        augsburg\n",
       "30741      consensus    consensus       consensus\n",
       "30742        planted        plant         planted\n",
       "\n",
       "[30743 rows x 3 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SBS = SnowballStemmer('english')\n",
    "WNL = WordNetLemmatizer()\n",
    "\n",
    "tb1 = [SBS.stem(i) for i in list(FD)]\n",
    "tb2 = [WNL.lemmatize(i) for i in list(FD)]\n",
    "df = pd.DataFrame([list(FD), tb1, tb2], index=['word', 'stemmed_word', 'normalized_word'])\n",
    "df = df.transpose()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8xEkpF6VcsLF"
   },
   "source": [
    "2.2. Удалите стоп-слова из описаний рецептов. Какую долю об общего количества слов составляли стоп-слова? Сравните топ-10 самых часто употребляемых слов до и после удаления стоп-слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop = stopwords.words('english')\n",
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'recipe': 14871, 'make': 6326, 'time': 5137, 'use': 4620, 'great': 4430, 'like': 4167, 'easy': 4152, 'one': 3872, 'made': 3810, 'good': 3791, ...})"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FD_modified = FreqDist([i for i in words if i not in stop])\n",
    "FD_modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('the', 40072),\n",
       "  ('a', 34951),\n",
       "  ('and', 30245),\n",
       "  ('this', 26859),\n",
       "  ('i', 24836),\n",
       "  ('to', 23471),\n",
       "  ('is', 20285),\n",
       "  ('it', 19756),\n",
       "  ('of', 18364),\n",
       "  ('for', 15939)],\n",
       " [('recipe', 14871),\n",
       "  ('make', 6326),\n",
       "  ('time', 5137),\n",
       "  ('use', 4620),\n",
       "  ('great', 4430),\n",
       "  ('like', 4167),\n",
       "  ('easy', 4152),\n",
       "  ('one', 3872),\n",
       "  ('made', 3810),\n",
       "  ('good', 3791)])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FD.most_common(10), FD_modified.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NT5J_hxvcsLG"
   },
   "source": [
    "### Векторное представление текста"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FHM71XurcsLG"
   },
   "source": [
    "3.1 Выберите случайным образом 5 рецептов из набора данных. Представьте описание каждого рецепта в виде числового вектора при помощи `TfidfVectorizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>preprocessed_descriptions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8466</th>\n",
       "      <td>crisp eggplant  aubergine  chips</td>\n",
       "      <td>found this in gourmets 50th anniversary additi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21916</th>\n",
       "      <td>quick chicken tortilla soup</td>\n",
       "      <td>quick easy and tasty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>apples with kahlua dip</td>\n",
       "      <td>this was an entry in rsc 10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4656</th>\n",
       "      <td>caramel iced coffee at home</td>\n",
       "      <td>i made this up cuz im in england with no mcdon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336</th>\n",
       "      <td>atkin induction friendly crustless quiche</td>\n",
       "      <td>this is a great recipe anytime but is perfect ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            name   \n",
       "8466            crisp eggplant  aubergine  chips  \\\n",
       "21916                quick chicken tortilla soup   \n",
       "1020                      apples with kahlua dip   \n",
       "4656                 caramel iced coffee at home   \n",
       "1336   atkin induction friendly crustless quiche   \n",
       "\n",
       "                               preprocessed_descriptions  \n",
       "8466   found this in gourmets 50th anniversary additi...  \n",
       "21916                               quick easy and tasty  \n",
       "1020                         this was an entry in rsc 10  \n",
       "4656   i made this up cuz im in england with no mcdon...  \n",
       "1336   this is a great recipe anytime but is perfect ...  "
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd = description.sample(5)\n",
    "rnd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['found this in gourmets 50th anniversary addition september 2006  i love chips made from veggies other than potatoes they are always a surprising treat  havent made these yet but i can just tell that theyll be great',\n",
       " 'quick easy and tasty',\n",
       " 'this was an entry in rsc 10',\n",
       " 'i made this up cuz im in england with no mcdonalds and i am addicted to their iced coffee',\n",
       " 'this is a great recipe anytime but is perfect for induction on the atkins diet  i like the crust that forms on the outside so i do use muffin tins instead of a pie shell']"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_descriptions = list(i for i in rnd.preprocessed_descriptions)\n",
    "preprocessed_descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.16959558, 0.16959558, 0.13682865, 0.        ,\n",
       "        0.16959558, 0.16959558, 0.        , 0.        , 0.        ,\n",
       "        0.16959558, 0.        , 0.16959558, 0.        , 0.16959558,\n",
       "        0.13682865, 0.16959558, 0.16959558, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.16959558, 0.16959558,\n",
       "        0.16959558, 0.13682865, 0.16959558, 0.22716028, 0.        ,\n",
       "        0.        , 0.11358014, 0.        , 0.        , 0.        ,\n",
       "        0.16959558, 0.        , 0.16959558, 0.2736573 , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.16959558,\n",
       "        0.        , 0.        , 0.        , 0.16959558, 0.        ,\n",
       "        0.        , 0.        , 0.16959558, 0.        , 0.        ,\n",
       "        0.16959558, 0.        , 0.16959558, 0.16959558, 0.13682865,\n",
       "        0.        , 0.        , 0.16959558, 0.16959558, 0.16959558,\n",
       "        0.09554719, 0.        , 0.        , 0.16959558, 0.        ,\n",
       "        0.        , 0.16959558, 0.        , 0.        , 0.16959558],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.42224214,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.52335825, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.52335825,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.52335825, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.41645294, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.41645294, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.41645294, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.27890339, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.41645294, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.23462232, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.41645294, 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.24352751,\n",
       "        0.        , 0.        , 0.24352751, 0.        , 0.19647646,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.24352751, 0.        ,\n",
       "        0.24352751, 0.        , 0.        , 0.        , 0.24352751,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.32618642, 0.24352751,\n",
       "        0.24352751, 0.16309321, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.19647646, 0.24352751,\n",
       "        0.        , 0.24352751, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.24352751, 0.        , 0.        , 0.        ,\n",
       "        0.13719915, 0.        , 0.24352751, 0.        , 0.24352751,\n",
       "        0.        , 0.        , 0.        , 0.24352751, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.2441808 , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.1513279 , 0.        , 0.1513279 , 0.        ,\n",
       "        0.1220904 , 0.        , 0.        , 0.        , 0.1513279 ,\n",
       "        0.        , 0.1513279 , 0.1513279 , 0.        , 0.        ,\n",
       "        0.        , 0.1513279 , 0.1513279 , 0.        , 0.        ,\n",
       "        0.        , 0.1220904 , 0.        , 0.20269212, 0.        ,\n",
       "        0.        , 0.        , 0.1513279 , 0.1513279 , 0.3026558 ,\n",
       "        0.        , 0.1513279 , 0.        , 0.        , 0.        ,\n",
       "        0.1513279 , 0.        , 0.1513279 , 0.3026558 , 0.        ,\n",
       "        0.1513279 , 0.1513279 , 0.1513279 , 0.        , 0.        ,\n",
       "        0.1513279 , 0.        , 0.        , 0.1513279 , 0.1513279 ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.1220904 ,\n",
       "        0.4539837 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.0852555 , 0.1513279 , 0.        , 0.        , 0.        ,\n",
       "        0.1513279 , 0.        , 0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TVectorizer = TfidfVectorizer(tokenizer=word_tokenize)\n",
    "FTrans = TVectorizer.fit_transform(preprocessed_descriptions)\n",
    "r = np.array(FTrans.todense())\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T5RPLxskcsLH"
   },
   "source": [
    "3.2 Вычислите близость между каждой парой рецептов, выбранных в задании 3.1, используя косинусное расстояние (`scipy.spatial.distance.cosine`) Результаты оформите в виде таблицы `pd.DataFrame`. В качестве названий строк и столбцов используйте названия рецептов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>name</th>\n",
       "      <th>crisp eggplant  aubergine  chips</th>\n",
       "      <th>quick chicken tortilla soup</th>\n",
       "      <th>apples with kahlua dip</th>\n",
       "      <th>caramel iced coffee at home</th>\n",
       "      <th>atkin induction friendly crustless quiche</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>crisp eggplant  aubergine  chips</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.945905</td>\n",
       "      <td>0.840503</td>\n",
       "      <td>0.862283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quick chicken tortilla soup</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.917039</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>apples with kahlua dip</th>\n",
       "      <td>0.945905</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.922323</td>\n",
       "      <td>0.979997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>caramel iced coffee at home</th>\n",
       "      <td>0.840503</td>\n",
       "      <td>0.917039</td>\n",
       "      <td>0.922323</td>\n",
       "      <td>0</td>\n",
       "      <td>0.922188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>atkin induction friendly crustless quiche</th>\n",
       "      <td>0.862283</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.979997</td>\n",
       "      <td>0.922188</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "name                                      crisp eggplant  aubergine  chips   \n",
       "name                                                                         \n",
       "crisp eggplant  aubergine  chips                                         0  \\\n",
       "quick chicken tortilla soup                                            1.0   \n",
       "apples with kahlua dip                                            0.945905   \n",
       "caramel iced coffee at home                                       0.840503   \n",
       "atkin induction friendly crustless quiche                         0.862283   \n",
       "\n",
       "name                                      quick chicken tortilla soup   \n",
       "name                                                                    \n",
       "crisp eggplant  aubergine  chips                                  1.0  \\\n",
       "quick chicken tortilla soup                                         0   \n",
       "apples with kahlua dip                                            1.0   \n",
       "caramel iced coffee at home                                  0.917039   \n",
       "atkin induction friendly crustless quiche                         1.0   \n",
       "\n",
       "name                                      apples with kahlua dip   \n",
       "name                                                               \n",
       "crisp eggplant  aubergine  chips                        0.945905  \\\n",
       "quick chicken tortilla soup                                  1.0   \n",
       "apples with kahlua dip                                         0   \n",
       "caramel iced coffee at home                             0.922323   \n",
       "atkin induction friendly crustless quiche               0.979997   \n",
       "\n",
       "name                                      caramel iced coffee at home   \n",
       "name                                                                    \n",
       "crisp eggplant  aubergine  chips                             0.840503  \\\n",
       "quick chicken tortilla soup                                  0.917039   \n",
       "apples with kahlua dip                                       0.922323   \n",
       "caramel iced coffee at home                                         0   \n",
       "atkin induction friendly crustless quiche                    0.922188   \n",
       "\n",
       "name                                      atkin induction friendly crustless quiche  \n",
       "name                                                                                 \n",
       "crisp eggplant  aubergine  chips                                           0.862283  \n",
       "quick chicken tortilla soup                                                     1.0  \n",
       "apples with kahlua dip                                                     0.979997  \n",
       "caramel iced coffee at home                                                0.922188  \n",
       "atkin induction friendly crustless quiche                                         0  "
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_dist = pd.DataFrame(index=rnd.name, columns=rnd.name)\n",
    "for i,j in itertools.product(range(len(r)), range(len(r))):\n",
    "    cos_dist.iloc[i, j] = distance.cosine(r[i], r[j])\n",
    "cos_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K862z3tTcsLH"
   },
   "source": [
    "3.3 Какие рецепты являются наиболее похожими? Прокомментируйте результат (словами)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "id": "WSxhPS-scsLI"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8405030422752956"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_dist.replace(0, 1).values.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('crisp eggplant  aubergine  chips', 'caramel iced coffee at home')"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = np.where(cos_dist == cos_dist.replace(0, 1).values.min())\n",
    "rnd.name.iloc[i[0][0]], rnd.name.iloc[i[0][1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Чем меньше косинусное расстояние, тем больше рецепты похожи друг на друга. Если расстояние == 0, то названия рецептов совпадают"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
